[
    {
        "model_alias": "internlm_nexusera",
        "template": "intern2",
        "model_name_or_path": "/mnt/windows/Users/Admin/LLM/models/Shanghai_AI_Laboratory/Nexusera_Extract_V1",
        "hf_path": "",
        "ms_path": "",
        "unsloth": "False",
        "description":"internlm-7B微调版本V1"
    },
    {
        "model_alias": "qwen2-7B-chat",
        "template": "qwen",
        "model_name_or_path": "/mnt/windows/Users/Admin/LLM/models/qwen/Qwen2-7B-Instruct",
        "hf_path": "Qwen/Qwen2-7B-Instruct",
        "ms_path": "qwen/Qwen2-7B-Instruct",
        "unsloth":"False"
    },
    {
        "model_alias": "glm-4-9b-chat",
        "template": "glm4",
        "model_name_or_path": "/mnt/windows/Users/Admin/LLM/models/ZhipuAI/glm-4-9b-chat",
        "hf_path": "",
        "ms_path": "",
        "unsloth": "False"
    },
    {
        "model_alias": "01-9B-Chat",
        "template": "yi",
        "model_name_or_path": "/mnt/windows/Users/Admin/LLM/models/01ai/Yi-1___5-9B-Chat/",
        "hf_path": "",
        "ms_path": "01ai/Yi-1.5-9B-Chat",
        "unsloth": "False"
    },
    {
        "model_alias": "llama3-8B-chinese-chat",
        "template": "llama3",
        "model_name_or_path": "/mnt/windows/Users/Admin/LLM/models/shenzhi-wang/Llama3-8B-Chinese-Chat",
        "hf_path": "",
        "ms_path": "",
        "unsloth": "True"
    },
    {
        "model_alias": "Qwen1.5-14B-int8",
        "template": "qwen",
        "model_name_or_path": "/mnt/windows/Users/Admin/LLM/models/qwen/Qwen1___5-14B-Chat-GPTQ-Int8",
        "hf_path": "",
        "ms_path": "",
        "unsloth": "False"
    },
    {
        "model_alias": "mixtral8x7_3bit",
        "template": "mistral",
        "model_name_or_path": "/mnt/windows/Users/Admin/LLM/models/n810x/Mixtral-8x7B-Instruct-v0.1-3bit-exl2",
        "hf_path": "",
        "ms_path": "",
        "unsloth": "True"
    }
]